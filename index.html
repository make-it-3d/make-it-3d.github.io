<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://junshutang.github.io/">Junshu Tang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://tengfei-wang.github.io/">Tengfei Wang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://bo-zhang.me/">Bo Zhang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/tinzhan/">Ting Zhang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://dmcv.sjtu.edu.cn/people/">Lizhuang Ma</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/doch/">Dong Chen</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
            <span class="author-block"><sup>2</sup>HKUST,</span>
            <span class="author-block"><sup>3</sup>Microsoft Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://make-it-3d.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/junshutang/Make-It-3D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/junshutang/Make-It-3D"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Make-It-3D</span> can create high-fidelity 3D content from only a single image.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%" width="90%">
            <source src="./static/videos/result-2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%" width="90%">
            <source src="./static/videos/result-3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%" width="90%">
            <source src="./static/videos/result-4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%" width="90%">
            <source src="./static/videos/result-5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%" width="90%">
            <source src="./static/videos/result-6.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we investigate the problem of creating high-fidelity 3D content from only a single image. 
            This is inherently challenging: it essentially involves estimating the underlying 3D geometry while simultaneously 
            hallucinating unseen textures. To address this challenge, we leverage prior knowledge from a well-trained 
            2D diffusion model to act as 3D-aware supervision for 3D creation. Our approach, <span class="dnerf">Make-It-3D</span>, 
            employs a two-stage optimization pipeline: the first stage optimizes a neural radiance field by incorporating 
            constraints from 
            the reference image at the frontal view and diffusion prior at novel views; the second stage transforms 
            the coarse model into textured point clouds and further elevates the realism with diffusion prior while 
            leveraging the high-quality textures from the reference image. Extensive experiments demonstrate that our 
            method outperforms prior works by a large margin, resulting in faithful reconstructions and impressive 
            visual quality. Our method presents the first attempt to achieve high-quality 3D creation from a single 
            image for general objects and enables various applications such as text-to-3D creation and texture editing.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline</h2>
        <div class="content has-text-justified">
        <p>
            Generating novel views for general scenes or objects from only a single image is inherently challenging 
            due to the difficulty of inferring both geometry and missing texture. We therefore tackle this challenge by 
            cultivating the dark knowledge of pretrained 2D diffusion models. 
        </p>
        <div>
            <img src="./static/images/pipeline.jpg" alt="method" class="center">
          </div>
        <p>
            Given an input image x, we first hallucinate its underlying 3D representation, neural radiance 
            field (NeRF), whose rendering appears as a plausible sample to a pretrained denoising diffusion model, and 
            we constrain this optimization process with the texture and depth supervision at the reference view. 
            To further improve the rendering realism, we keep the learned geometry and enhance the textures with the 
            reference image. As such, in the second stage, we lift the input image to textured point clouds and focus 
            on refining the color of the points occluded in the reference view. We leverage prior knowledge of the 
            text-to-image generative model and the text-image contrastive model for both stages. 
            In this way, we achieve a faithful 3D representation of the input image with restored high-fidelity texture and geometry.
        </p>
          </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->



<footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The website code is borrowed from the <a
                href="https://github.com/nerfies/nerfies.github.io">source code</a> of Nerfies. We thank the authors for sharing the templates.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
